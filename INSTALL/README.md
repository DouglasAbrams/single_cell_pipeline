# Installation and test run

1. clone the single cell pipeline repo.
	```
	export GIT_SSL_NO_VERIFY=1
	git clone https://dgrewal@svn.bcgsc.ca/bitbucket/scm/sc/single_cell_pipeline.git
	```
2. install miniconda
	```
	wget https://repo.continuum.io/miniconda/Miniconda2-latest-Linux-x86_64.sh
	sudo bash Miniconda2-latest-Linux-x86_64.sh -b -p /usr/local/miniconda2
	echo "export PATH=/usr/local/miniconda2/bin:$PATH" >> ~/.bashrc
	source ~/.bashrc
	sudo chmod -R 775 /usr/local/miniconda2/
	```
3.  update conda
	```
	conda upgrade  conda -y
	```
4.  add conda channels
	```
	conda config --add channels https://conda.anaconda.org/dranew
	conda config --add channels 'bioconda'
	conda config --add channels 'r'
	conda config --add channels 'conda-forge'
	conda config --add channels https://conda.anaconda.org/aroth85
	```
5.  Install Dependencies
	```
	conda install --file single_cell_pipeline/conda_packages.txt
	```
6. install single_cell pipeline
	```
	cd  single_cell_pipeline/ && python setup.py install && cd ../
	```
7. install pypeliner
	```
	pip install git+https://dgrewal@bitbucket.org/dranew/pypeliner.git@master
	pip install git+https://bitbucket.org/aroth85/biowrappers.git@singlecell
	```
8. download test data
	```
	mkdir data
	cd data
	wget https://singlecelldata.blob.core.windows.net/dlp-paper/SA123_R1.fastq.gz
	wget https://singlecelldata.blob.core.windows.net/dlp-paper/SA123_R2.fastq.gz
	wget https://singlecelldata.blob.core.windows.net/dlp-paper/SA456_R1.fastq.gz
	wget https://singlecelldata.blob.core.windows.net/dlp-paper/SA456_R2.fastq.gz
	cd ../
	```
9. Download reference data:
	```
	wget https://singlecelldata.blob.core.windows.net/dlp-paper/refdata.tar.gz
	sudo mkdir /refdata
	sudo tar -xvf refdata.tar.gz -C /
	```
	*If you don't have permissions to write to /refdata directory, please feel free to extract it someplace else. see the note in step 12*
10. build pipeline input file.
	   The pipeline takes a yaml formatted input file with paths to fastq files, aligned bam files (will be generated by the pipeline) and metadata.
	```
	SA123:
	  bam: data/SA123.bam
	  column: 1
	  condition: A
	  fastqs:
	    LANE_1:
	      fastq_1: data/SA123_R1.fastq.gz
	      fastq_2: data/SA123_R2.fastq.gz
	      sequencing_center: BCCAGSC
	      sequencing_instrument: HX
	  img_col: 2
	  index_i5: i5-1
	  index_i7: i7-2
	  pick_met: A1
	  primer_i5: AACCGGTT
	  primer_i7: ACGTACGT
	  row: 3
	  sample_type: null
	SA456:
	  bam: data/SA456.bam
	  column: 4
	  condition: A
	  fastqs:
	    LANE_1:
	      fastq_1: data/SA456_R1.fastq.gz
	      fastq_2: data/SA456_R2.fastq.gz
	      sequencing_center: BCCAGSC
	      sequencing_instrument: HX
	  img_col: 5
	  index_i5: i5-1
	  index_i7: i7-2
	  pick_met: B1
	  primer_i5: AACCGGTT
	  primer_i7: ACGTACGT
	  row: 6
	  sample_type: null
	``` 
12. generate the sample pipeline config file
	```
	single_cell generate_config --pipeline_config config.yaml
	```
	If reference data is not in /refdata, then please update the following values to the correct path in the config.yaml file
	```gc_windows: /refdata/gc_windows.txt```
	```ref_genome: /refdata/GRCh37-lite.fa```
	```
    hmmcopy_params:
	  autoploidy:
        exclude_list: /refdata/repeats.satellite.regions
	```
	```
    hmmcopy_params:
      autoploidy:
        gc_wig_file: /refdata/GRCh37-lite.gc.ws_500000.wig
	```
	```
    hmmcopy_params:
      autoploidy:
        map_wig_file: /refdata/GRCh37-lite.map.ws_125_to_500000.wig
	```
13. align the fastq pairs:
	```
	single_cell align --input_yaml input.yaml --out_dir dlp --submit local --library_id A123456 --loglevel DEBUG --tmpdir temp --pipelinedir pipeline --maxjobs 2
	```
    *Outputs:*
    * ```data/SA123.bam``` and ```data/SA456.bam```: aligned bam files
    * ```dlp/results/alignment/A123456_alignment_metrics.h5```: alignment metrics and metadata
    * ```dlp/results/alignment/plots/A123456_plot_metrics.pdf```: alignment QC plots.
14. run HMMCopy
	```
	single_cell hmmcopy --input_yaml input.yaml --out_dir dlp --submit local --library_id A123456 --loglevel DEBUG --tmpdir temp --pipelinedir pipeline --maxjobs 2
	```

    *Outputs:*

	* ```dlp/results/hmmcopy_autoploidy/A123456_hmmcopy.h5``` with data from hmmcopy
    * ```dlp/results/hmmcopy_autoploidy/A123456_igv_segments.seg``` to load segments in IGV
    * ```dlp/results/hmmcopy_autoploidy/plots/A123456_heatmap_by_ec.pdf ```: copy number heatmap
    * ```dlp/results/hmmcopy_autoploidy/plots/A123456_heatmap_by_ec_filtered.pdf ```: heatmap with filters to remove bad cells
    * ```dlp/results/hmmcopy_autoploidy/plots/A123456_kernel_density.pdf ```: kernel density plot
    * ```dlp/results/hmmcopy_autoploidy/plots/A123456_metrics.pdf ``` hmmcopy metrics
    * ```dlp/results/hmmcopy_autoploidy/plots/bias ``` GC bias plots
    * ```dlp/results/hmmcopy_autoploidy/plots/segments ``` hmmcopy segments
