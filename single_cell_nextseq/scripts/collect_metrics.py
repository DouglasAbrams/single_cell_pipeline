'''
Extract metrics table.
'''

from __future__ import division

import argparse
import pandas as pd
from __builtin__ import True
import warnings
import os

#=========================================================================
# Read Command Line Input
#=========================================================================
parser = argparse.ArgumentParser()

parser.add_argument('flagstat_metrics',
                    help='''Path to metrics directory generated by alignment pipeline.''')

parser.add_argument('markdups_metrics',
                    help='''Path to metrics directory generated by alignment pipeline.''')

parser.add_argument('insert_metrics',
                    help='''Path to metrics directory generated by alignment pipeline.''')

parser.add_argument('wgs_metrics',
                    help='''Path to metrics directory generated by alignment pipeline.''')

parser.add_argument('out_file',
                    help='''Path to .csv file where table output will be written.''')

parser.add_argument('sample_id',
                    help=''' identifier string for the library.''')

args = parser.parse_args()

#=========================================================================
# Functions
#=========================================================================


def extract_wgs_metrics(metrics_file):
    """
    get the coverage_depth (mean_coverage column)
    get the coverage_breadth (count/genome_territory)
    """

    mfile = open(metrics_file)
    
    metrics = []
    hist = {}
    
    addmetrics = False
    addhist = False
   
   
    for line in mfile:
        if line.strip() == '':
            continue
        if line.startswith('## METRICS CLASS'):
            addmetrics = True
            addhist = False
            continue

        if line.startswith('## HISTOGRAM'):
            addhist = True
            addmetrics = False
            continue
        
        if addmetrics:
            metrics.append(line.strip().split('\t'))
        if addhist:
            line = line.strip().split('\t')
            if line[0] == 'coverage':
                continue
            hist[int(line[0])] = int(line[1])

    mfile.close()
    header, data = metrics

    header = [v.lower() for v in header]
    header = {v:i for i,v in enumerate(header)}

    gen_territory = int(data[header['genome_territory']])
    cov_depth  = float(data[header['mean_coverage']])
    count = int(hist[0])
    cov_breadth = (gen_territory - count) / gen_territory 

    return cov_breadth, cov_depth


def extract_flagstat_metrics(metrics_file):
    """
    extract from flagstat
    """

    df = pd.read_table(metrics_file,
                       sep=r'\s\+\s0\s',
                       header=None,
                       names=['value', 'type'],
                       engine='python')

    tot_reads = df[df['type']=='in total (QC-passed reads + QC-failed reads)']['value']
    tot_mpd_reads = df[(df['type'].str.contains('mapped') == True ) & ( df['type'].str.contains('mate mapped') == False)]
    tot_dup_reads = df[df['type']=='duplicates']['value']
    tot_prop_paired = df[df['type'].str.contains('properly paired') ]

    assert len(tot_reads) == 1
    assert len(tot_mpd_reads) == 1
    assert len(tot_dup_reads) == 1
    assert len(tot_prop_paired) == 1

    tot_reads = tot_reads.iloc[0]
    tot_mpd_reads = tot_mpd_reads['value'].iloc[0]
    tot_dup_reads = tot_dup_reads.iloc[0]
    tot_prop_paired = tot_prop_paired['value'].iloc[0]


    return tot_reads, tot_mpd_reads, tot_dup_reads, tot_prop_paired

def extract_duplication_metrics(metrics_file):
    """
    extract from markdups
    """

    mfile = open(metrics_file)

    targetlines = []

    line = mfile.readline()

    while line != '':
        if line.startswith('## METRICS CLASS'):
            targetlines.append(mfile.readline().strip('\n').split('\t'))
            targetlines.append(mfile.readline().strip('\n').split('\t'))
            break
        line = mfile.readline()

    mfile.close()

    header, data = targetlines

    header = [v.lower() for v in header]
    header = {v:i for i,v in enumerate(header)}

    unprd_mpd_rds = int(data[header['unpaired_reads_examined']])
    prd_mpd_rds = int(data[header['read_pairs_examined']])
    unprd_dup_rds = int(data[header['unpaired_read_duplicates']])
    prd_dup_rds = int(data[header['read_pair_duplicates']])
    unmpd_rds = data[header['unmapped_reads']]
    est_lib_size = data[header['estimated_library_size']]

    rd_pair_opt_dup = int(data[header['read_pair_optical_duplicates']])

    try:
        perc_dup_reads = (unprd_dup_rds + ((prd_dup_rds + rd_pair_opt_dup) * 2)) / (unprd_mpd_rds + (prd_mpd_rds * 2))
    except ZeroDivisionError:
        perc_dup_reads = 0

    outdata = (unprd_mpd_rds, prd_mpd_rds, unprd_dup_rds, prd_dup_rds,
               unmpd_rds, perc_dup_reads, est_lib_size)

    outdata = tuple(['nan' if val == '' else val for val in outdata])
    return outdata

def extract_insert_metrics(metrics_file):
    ''' Extract median and mean insert size '''

    # picardtools insertmetrics completes with code 0 and doesn't generate metrics file
    # if inputs don't have sufficient read count
    if not os.path.isfile(metrics_file):
        return 0, 0, 0

    mfile = open(metrics_file)
    
    targetlines = []
    
    line = mfile.readline()

    # Check whether a dummy file has been written in case of picard insert metrics failure
    if 'FAILED' in line:
        return 0, 0, 0
    
    while line != '':
        if line.startswith('## METRICS CLASS'):
            targetlines.append(mfile.readline().strip().split('\t'))
            targetlines.append(mfile.readline().strip().split('\t'))
            break
        line = mfile.readline()

    mfile.close()

    header, data = targetlines

    header = [v.lower() for v in header]
    header = {v:i for i,v in enumerate(header)}

    median_ins_size = data[header['median_insert_size']]
    mean_ins_size = data[header['mean_insert_size']]
    std_dev_ins_size = data[header['standard_deviation']]

    return median_ins_size, mean_ins_size, std_dev_ins_size


def write_data(header, data):
    """
    write to the output
    """
    assert len(header) == len(data)
    #replace empty vals with NA
    data = [v if v != '' else 'NA' for v in data]

    writer = open(args.out_file, 'w')
    writer.write(','.join(header) + '\n')
    writer.write(','.join([str(v) for v in data]))
    writer.close()


def extract_sample_info(sample_info):
    """
    get info
    """
    sample_info = open(sample_info)

    header = sample_info.readline()
    header = header.strip().split(',')
    header = {v:i for i,v in enumerate(header)}

    sampdata = sample_info.readline()

    assert sample_info.readline() == ''

    sampdata = sampdata.strip().split(',')
    samp = sampdata[header['sample_id']]
    well = sampdata[header['sample_well']]
    desc = sampdata[header['sample_description']]
    plate = sampdata[header['sample_plate']]
    i5 = sampdata[header['i5_barcode']]
    i7 = sampdata[header['i7_barcode']]
    if ';' in desc:
        desc = desc.split(';')
        cell_call = desc[0].replace('CC=','')
        exp_cond = desc[1].replace('EC=','')
    elif desc == '':
        cell_call = 'C1'
        exp_cond = 'A'
    else:
        cell_call = desc
        exp_cond = 'NA'

    well = well if well != '' else 'R1_C1'
    plate = plate if plate !='' else 'R1-C1'
    i5 = i5 if i5!='' else 'i5-1'
    i7 = i7  if i7 != '' else 'i7-1'


    return samp, cell_call, exp_cond, well, plate, i5, i7

#=========================================================================
# Run script
#=========================================================================

def main():

    duplication_metrics = extract_duplication_metrics(args.markdups_metrics)
    flagstat_metrics = extract_flagstat_metrics(args.flagstat_metrics)
    wgs_metrics = extract_wgs_metrics(args.wgs_metrics)

    header = ['sample_id',
              'unpaired_mapped_reads', 'paired_mapped_reads', 'unpaired_duplicate_reads',
              'paired_duplicate_reads', 'unmapped_reads', 'percent_duplicate_reads',
              'estimated_library_size', 'total_reads', 'total_mapped_reads',
              'total_duplicate_reads', 'total_properly_paired',
              'coverage_breadth', 'coverage_depth']

    output = (args.sample_id,) + duplication_metrics + flagstat_metrics + wgs_metrics

    if args.insert_metrics:
        insert_metrics = extract_insert_metrics(args.insert_metrics)
        output += insert_metrics
        header += ['median_insert_size',
                   'mean_insert_size',
                   'standard_deviation_insert_size']

    write_data(header, output)

if __name__ == '__main__':
    main()

